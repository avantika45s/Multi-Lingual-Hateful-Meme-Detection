{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11308580,"sourceType":"datasetVersion","datasetId":7072460}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers pandas tqdm\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-07T09:46:24.036951Z","iopub.execute_input":"2025-04-07T09:46:24.037276Z","iopub.status.idle":"2025-04-07T09:46:28.151641Z","shell.execute_reply.started":"2025-04-07T09:46:24.037246Z","shell.execute_reply":"2025-04-07T09:46:28.150583Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nfrom transformers import MarianTokenizer, MarianMTModel\nfrom tqdm import tqdm\n\n# Load model and tokenizer for Chinese → English\nmodel_name = \"Helsinki-NLP/opus-mt-zh-en\"\ntokenizer = MarianTokenizer.from_pretrained(model_name)\nmodel = MarianMTModel.from_pretrained(model_name)\n\n# Load the CSV file (change filename if needed)\n# df = pd.read_csv(\"/kaggle/input/chinese-text/C_text.csv\").head(10)  # assuming column is 'chinese_text'\ndf = pd.read_csv(\"/kaggle/input/chinese-text/C_text.csv\", encoding='gb18030').head(10)\n\n# Translation function\ndef translate(text):\n    if not isinstance(text, str) or text.strip() == \"\":\n        return \"\"\n    batch = tokenizer.prepare_seq2seq_batch([text], return_tensors=\"pt\")\n    gen = model.generate(**batch, max_new_tokens=100)\n    return tokenizer.decode(gen[0], skip_special_tokens=True)\n\n# Apply translation\ntqdm.pandas()\ndf[\"translated_english\"] = df[\"text\"].progress_apply(translate)\n\n# Save result\ndf.to_csv(\"translated_chinese_10rows.csv\", index=False)\nprint(\"✅ Chinese to English translation done. Saved to translated_chinese_10rows.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T09:48:21.220998Z","iopub.execute_input":"2025-04-07T09:48:21.221381Z","iopub.status.idle":"2025-04-07T09:48:28.012943Z","shell.execute_reply.started":"2025-04-07T09:48:21.221352Z","shell.execute_reply":"2025-04-07T09:48:28.011959Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:4079: FutureWarning: \n`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n`__call__` method to prepare your inputs and targets.\n\nHere is a short example:\n\nmodel_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n\nIf you either need to use different keyword arguments for the source and target texts, you should do two calls like\nthis:\n\nmodel_inputs = tokenizer(src_texts, ...)\nlabels = tokenizer(text_target=tgt_texts, ...)\nmodel_inputs[\"labels\"] = labels[\"input_ids\"]\n\nSee the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\nFor a more complete example, see the implementation of `prepare_seq2seq_batch`.\n\n  warnings.warn(formatted_warning, FutureWarning)\n100%|██████████| 10/10 [00:04<00:00,  2.09it/s]","output_type":"stream"},{"name":"stdout","text":"✅ Chinese to English translation done. Saved to translated_chinese_10rows.csv\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":3}]}