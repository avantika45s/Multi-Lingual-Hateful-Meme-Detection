{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11309140,"sourceType":"datasetVersion","datasetId":7072892}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers pandas tqdm\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-07T10:36:56.357164Z","iopub.execute_input":"2025-04-07T10:36:56.357546Z","iopub.status.idle":"2025-04-07T10:36:59.715788Z","shell.execute_reply.started":"2025-04-07T10:36:56.357516Z","shell.execute_reply":"2025-04-07T10:36:59.714791Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nfrom transformers import MarianTokenizer, MarianMTModel\nfrom tqdm import tqdm\n\n# Load model and tokenizer for Bengali → English\nmodel_name = \"Helsinki-NLP/opus-mt-bn-en\"\ntokenizer = MarianTokenizer.from_pretrained(model_name)\nmodel = MarianMTModel.from_pretrained(model_name)\n\n# Load your Bengali text CSV (change filename and encoding if needed)\ndf = pd.read_csv(\"/kaggle/input/bengali-text-2/Bengali_text.csv\", encoding='utf-8-sig').head(10)  # Column: 'bengali_text'\n\n# Translate function\ndef translate_bn_to_en(text):\n    if not isinstance(text, str) or text.strip() == \"\":\n        return \"\"\n    batch = tokenizer.prepare_seq2seq_batch([text], return_tensors=\"pt\")\n    gen = model.generate(**batch, max_new_tokens=100)\n    return tokenizer.decode(gen[0], skip_special_tokens=True)\n\n# Apply translation with progress bar\ntqdm.pandas()\ndf[\"translated_english\"] = df[\"Captions\"].progress_apply(translate_bn_to_en)\n\n# Save output\ndf.to_csv(\"translated_bengali_10rows.csv\", index=False)\nprint(\"✅ Bengali to English translation complete. Saved to translated_bengali_10rows.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T10:37:21.312041Z","iopub.execute_input":"2025-04-07T10:37:21.312390Z","iopub.status.idle":"2025-04-07T10:37:56.047124Z","shell.execute_reply.started":"2025-04-07T10:37:21.312361Z","shell.execute_reply":"2025-04-07T10:37:56.046107Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2659c19da1f43d6a835f54ea70e7276"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"source.spm:   0%|          | 0.00/1.12M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"944e422aa42749908ba1bd81edde3a63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"target.spm:   0%|          | 0.00/806k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"249d89dd38ba403da479307c0768d54f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.25M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f33f38e627e8426a8661979087994f95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7323c752a9414aab96da4b56397bfefa"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/309M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edeedc407d6246bb90f64a121d4060dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c83e4188c7549a3b8dd396a3f6d3676"}},"metadata":{}},{"name":"stderr","text":"  0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:4079: FutureWarning: \n`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n`__call__` method to prepare your inputs and targets.\n\nHere is a short example:\n\nmodel_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n\nIf you either need to use different keyword arguments for the source and target texts, you should do two calls like\nthis:\n\nmodel_inputs = tokenizer(src_texts, ...)\nlabels = tokenizer(text_target=tgt_texts, ...)\nmodel_inputs[\"labels\"] = labels[\"input_ids\"]\n\nSee the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\nFor a more complete example, see the implementation of `prepare_seq2seq_batch`.\n\n  warnings.warn(formatted_warning, FutureWarning)\n100%|██████████| 10/10 [00:08<00:00,  1.13it/s]","output_type":"stream"},{"name":"stdout","text":"✅ Bengali to English translation complete. Saved to translated_bengali_10rows.csv\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\nimport re\nfrom transformers import MarianMTModel, MarianTokenizer\n\n# Bengali to English model and tokenizer\nmodel_name = \"Helsinki-NLP/opus-mt-bn-en\"\ntokenizer_bn_en = MarianTokenizer.from_pretrained(model_name)\nmodel_bn_en = MarianMTModel.from_pretrained(model_name)\n\n# Function to detect Bengali script using Unicode\nbengali_pattern = re.compile(r'[\\u0980-\\u09FF]')\n\ndef contains_bengali(text):\n    return bool(bengali_pattern.search(text))\n\n# Function to translate Bengali to English\ndef translate_bn_to_en(text):\n    if not isinstance(text, str) or text.strip() == \"\":\n        return \"\"\n    batch = tokenizer_bn_en.prepare_seq2seq_batch([text], return_tensors=\"pt\")\n    gen = model_bn_en.generate(**batch)\n    return tokenizer_bn_en.decode(gen[0], skip_special_tokens=True)\n\n# Final logic to translate only if Bengali detected\ndef smart_translate(text):\n    if pd.isna(text) or not isinstance(text, str):\n        return \"\"\n    if contains_bengali(text):\n        return translate_bn_to_en(text)\n    return text\n\n# Load your CSV file (change path to your actual file path)\nfile_path = \"/kaggle/input/bengali-text-2/Bengali_text.csv\"  # 📝 update this\ndf = pd.read_csv(file_path, encoding=\"utf-8\")\n\n# Process first 10 rows only for testing\ndf_subset = df.head(10).copy()\n\n# Change 'text_column_name' to the actual name in your CSV (e.g., 'text')\ndf_subset['translated_text'] = df_subset['Captions'].apply(smart_translate)\n\n# Save output to new CSV (optional)\ndf_subset.to_csv(\"translated_output.csv\", index=False)\n\n# Display the result\nprint(df_subset[['Captions', 'translated_text']])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T10:44:23.220745Z","iopub.execute_input":"2025-04-07T10:44:23.221163Z","iopub.status.idle":"2025-04-07T10:44:31.769044Z","shell.execute_reply.started":"2025-04-07T10:44:23.221119Z","shell.execute_reply":"2025-04-07T10:44:31.768053Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:4079: FutureWarning: \n`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n`__call__` method to prepare your inputs and targets.\n\nHere is a short example:\n\nmodel_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n\nIf you either need to use different keyword arguments for the source and target texts, you should do two calls like\nthis:\n\nmodel_inputs = tokenizer(src_texts, ...)\nlabels = tokenizer(text_target=tgt_texts, ...)\nmodel_inputs[\"labels\"] = labels[\"input_ids\"]\n\nSee the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\nFor a more complete example, see the implementation of `prepare_seq2seq_batch`.\n\n  warnings.warn(formatted_warning, FutureWarning)\n","output_type":"stream"},{"name":"stdout","text":"                                            Captions  \\\n0  আম্মাঃ HSC চলে আসছে , এখন থেকে তোর মোবাইল , ল্...   \n1  WHEN YOUR COUSINS TAKES YOU TO THE DHAN KHET A...   \n2  WHEN HE SAID 10 MINUTES BUT IT WAS ONLY 2 MINUTES   \n3  SHE - I CAN'T BE WITH YOU   -তবে শেষবারের মত দ...   \n4  যখন কোন Teacher বলে   \"সত্যটা বলো, তাহলে আর কি...   \n5  আয়মান সাদিক    ব্যয়মান সাদিক    পরমমান সাদিক  ...   \n6  When your younger brothers asks  \"ভাইয়া আমরা ক...   \n7  WHEN YOU ARE ABOUT TO BANG HER & SHE SAYS দাঁড়...   \n8  BIOLOGY THEORY IS IMPORTANT BUT, BIOLOGY PRACT...   \n9  Nije kono content Create kora    Onno ke hoga ...   \n\n                                     translated_text  \n0  Amma: HC is coming back, your mobile, laptop's...  \n1  WHEN YOUR COUSINS TAKES YOU TO THE DHAN KHET A...  \n2  WHEN HE SAID 10 MINUTES BUT IT WAS ONLY 2 MINUTES  \n3           SHE-ICAT: Let's see it for the last time  \n4  When you say something, \"Speak the truth, then...  \n5                      Ayman Sadýk Damak Sadýk Sadýk  \n6                           Where did you come from?  \n7  We're gonna get this baby to sleep, yeah WP8O ...  \n8  BIOLOGLE RIPORT URNAT, BITILOGET ENCLES LIECIE...  \n9  Nije kono content Create kora    Onno ke hoga ...  \n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Best among others on 10 rows","metadata":{}},{"cell_type":"code","source":"!pip install transformers sentencepiece pandas langdetect\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T10:46:13.259489Z","iopub.execute_input":"2025-04-07T10:46:13.259873Z","iopub.status.idle":"2025-04-07T10:46:18.994375Z","shell.execute_reply.started":"2025-04-07T10:46:13.259828Z","shell.execute_reply":"2025-04-07T10:46:18.993376Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\nCollecting langdetect\n  Downloading langdetect-1.0.9.tar.gz (981 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.17.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nBuilding wheels for collected packages: langdetect\n  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=fce52e5074bd7df602196ea7ca26d8783565f2c06e9c666842a517994b2080fa\n  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\nSuccessfully built langdetect\nInstalling collected packages: langdetect\nSuccessfully installed langdetect-1.0.9\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import pandas as pd\nfrom transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\nfrom langdetect import detect\n\n# Load model and tokenizer\nmodel_name = \"facebook/m2m100_418M\"\ntokenizer = M2M100Tokenizer.from_pretrained(model_name)\nmodel = M2M100ForConditionalGeneration.from_pretrained(model_name)\n\n# Load your dataset (update with your CSV file)\ndf = pd.read_csv(\"/kaggle/input/bengali-text-2/Bengali_text.csv\", encoding='utf-8')\n\n# Work with just first 10 rows for now\nsample_df = df.head(10)\n\ndef detect_and_translate(text):\n    try:\n        lang = detect(text)\n        if lang not in tokenizer.lang_code_to_id:\n            lang = \"bn\"  # fallback for Bengali/Hinglish mix\n        tokenizer.src_lang = lang\n\n        encoded = tokenizer(text, return_tensors=\"pt\")\n        generated = model.generate(**encoded, forced_bos_token_id=tokenizer.lang_code_to_id[\"en\"])\n        translated = tokenizer.batch_decode(generated, skip_special_tokens=True)[0]\n        return translated\n    except Exception as e:\n        print(f\"Translation failed for: {text}\")\n        return text\n\n# Add translation column\nsample_df[\"translated_text\"] = sample_df[\"Captions\"].apply(detect_and_translate)\n\n# # Change 'text_column_name' to the actual name in your CSV (e.g., 'text')\n# df_subset['translated_text'] = df_subset['Captions'].apply(smart_translate)\n\n# Save output to new CSV (optional)\nsample_df.to_csv(\"translated_output_m2m.csv\", index=False)\n\n# Show result\nprint(sample_df[[\"Captions\", \"translated_text\"]])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T10:49:20.024239Z","iopub.execute_input":"2025-04-07T10:49:20.024591Z","iopub.status.idle":"2025-04-07T10:49:59.497467Z","shell.execute_reply.started":"2025-04-07T10:49:20.024565Z","shell.execute_reply":"2025-04-07T10:49:59.496467Z"}},"outputs":[{"name":"stdout","text":"                                            Captions  \\\n0  আম্মাঃ HSC চলে আসছে , এখন থেকে তোর মোবাইল , ল্...   \n1  WHEN YOUR COUSINS TAKES YOU TO THE DHAN KHET A...   \n2  WHEN HE SAID 10 MINUTES BUT IT WAS ONLY 2 MINUTES   \n3  SHE - I CAN'T BE WITH YOU   -তবে শেষবারের মত দ...   \n4  যখন কোন Teacher বলে   \"সত্যটা বলো, তাহলে আর কি...   \n5  আয়মান সাদিক    ব্যয়মান সাদিক    পরমমান সাদিক  ...   \n6  When your younger brothers asks  \"ভাইয়া আমরা ক...   \n7  WHEN YOU ARE ABOUT TO BANG HER & SHE SAYS দাঁড়...   \n8  BIOLOGY THEORY IS IMPORTANT BUT, BIOLOGY PRACT...   \n9  Nije kono content Create kora    Onno ke hoga ...   \n\n                                     translated_text  \n0  Mom: HSC is coming, from now on your mobile, l...  \n1  When your cousins touch you to the DHAN KHET a...  \n2    When he left 10 minutes, it was just 2 minutes.  \n3  SHE - I can't be with you - but let it look li...  \n4  When a teacher says, “Tell the truth, I’ll say...  \n5    Sadiq Sadiq Sadiq Sadiq Sadiq Sadiq Sadiq Sadiq  \n6   When your younger brothers asks, “How do we be?”  \n7  When you are about to ban her and she says sta...  \n8  Biology Theory Is Important But Biology Practi...  \n9  No Kono content Create kora Onno ke hoga mere ...  \n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-9-2b76079c7045>:32: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  sample_df[\"translated_text\"] = sample_df[\"Captions\"].apply(detect_and_translate)\n","output_type":"stream"}],"execution_count":9}]}